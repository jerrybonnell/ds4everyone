## A/B Test

In the previous section, we study the use of hypothesis testing.
Here in this section, we learn a simple method to compare two distributions using a method we call *A/B Test*.
The idea behind A/B testing is this as follows.

* We have two sets of numerical data A and B, which respectively have the mean values $a$ and $b$, with difference $d = a - b$. We will swap A and B if necessary so that $a > b$.
* We want to know, assuming that the two data sets have the same origin, how large (or small) chances are that the difference of $d$ emerges when we redivide the join of A and B into two groups, only retaining the sizes of A and B.
* For each such random split, we compute the difference in the mean values.
* By repeating such random splits many times, we can obtain distributions of the means.

### Some Preparation


Let us begin by loading `tidyverse`.

```{r}
library(tidyverse)
```

In making random splits, we define a function that generates, given a number `c`, a random sequence of integers between 1 and `c`.

```{r}
rand_perm <- function(c) {
  y <- 1:c
  for (i in c:2) {
    ll <- sample(1:c, size=1, replace=TRUE)
    j <- ll[1]  
    a <- y[j]
    y[j] <- y[i]
    y[i] <- a
  }
  return(y)
}
print(rand_perm(11))
```

The function `mean_diff_single` is one that receives two lists, `x` and `y`, merges the two input one, and then splits it into two lists having the same sizes as `x` and `y`, respectively.
The function then computes the mean for each of the two new lists and returns the difference betwwen the two means.

In random splitting, the function uses the `rand_perm` function.

```{r}
mean_diff_single <- function(x,y) {
  l1 = length(x)
  l2 = length(y)
  l0 = l1 + l2
  z <- append(x,y)
  ch <- rand_perm(l0)
  #print(z)
  #print(ch)
  z1 <- vector("double", l1)
  for (i in 1:l1) {
    z1[i] <- z[ch[i]]
  }
  z2 <- vector("double", l2)
  for (i in 1:l2) {
    z2[i] <- z[ch[l1 + i]]
  }
  #print(z1)
  #print(z2)
  m1 <- mean(z1)
  m2 <- mean(z2)
  #print(m1)
  #print(m2)
  return(m1 - m2)
}
mean_diff_single(c(1,2,3),c(4,-5,6))
```

We now define a function that receives two lists and a count `c`, executes the random split `c` times and returns the list of `c` mean differences.
```{r}
mean_diff_multi <- function(x,y,c) {
  results <- vector("double",c)
  for (j in 1:c) {
    results[j] <- mean_diff_single(x,y)
  }
  return(results)
}
r <- mean_diff_multi(c(1,2,3,4,5),c(6,8,10,12,24),5)
print(r)
```

### Comparing NCAA Receivers from Different Years

```{r}
receivers <- read_csv("data/nfl_receivers.csv")
spec(receivers)
receivers2017 <- filter(receivers, Year == 2017)
receivers2019 <- filter(receivers, Year == 2019)
yards17 <- receivers2017$Yds
yards19 <- receivers2019$Yds

```


```{r}
diff0 <- mean(yards17) - mean(yards19)
diff_data <- mean_diff_multi(yards17,yards19,1000)
```

```{r}
length(yards17)
length(yards19)
diff_data[1:10]
diff0
max(diff_data)
min(diff_data)
mean(diff_data)
```

```{r dpi=80,  fig.align="center", message = FALSE}
df <- tibble(diff_data)
mean_of_means <- mean(diff_data)
ggplot(df, aes(x = diff_data, y = ..density..)) + 
  geom_histogram(col="grey", breaks = seq(-45, 75, 10)) +
  geom_point(aes(x = diff0, y = 0), color = "red", size = 3)
```

Where does the mean different sit in the distribution of the differences?
We can calculate by obtaining a sub-list of `diff_data` with "less than `diff0`" as a filter and then computing the ratio of the length of the sub-list to the length of th original.

```{r}
#diff_data < diff0
length(diff_data[diff_data < diff0]) / length(diff_data)

```

The result is 0.289.
This means that the position of the mean difference is at 28.9% of the distribution of means.
We can safely accept the Null Hypothesis (the question we are asking - are the two data sets of the same origin).

### Comparing NFL and NCAA

Here is a data set of NCAA receivers.



```{r}
path0 <- "data/ncaa-reivers-2005-2011.csv"
ncaa0 <- read_csv(path0)
```

The data set has a large number of rows (7323).
The yardage information appears in `Yards`.


```{r}
spec(ncaa0)
nrow(ncaa0)
c(max(ncaa0$Year),min(ncaa0$Year))
```

Let us the NCAA data for 2011 and NFL 2019 and 2018 (which is the equivalent to Year not equal to 2017).
```{r}
ncaaYards <- filter(ncaa0, Year==2011)$Yards
nflYards <- filter(receivers, Year!=2017)$Yds
length(ncaaYards)
length(nflYards)
```

The two lists about the same lengths.
As before, let us compute the difference between the means of the two lists and then plot the data.

```{r}
diff1 <- mean(nflYards) - mean(ncaaYards)
diff1_data <- mean_diff_multi(nflYards,ncaaYards,1000)
min(diff1_data)
diff1
```

While the difference of the means is -53.9, the mean difference by sampling produced the minimum of -44.88.
This means that the probability that we observe the difference at hand is 0.

```{r}
df <- tibble(diff1_data)
mean_of_means <- mean(diff1_data)
ggplot(df, aes(x = diff1_data, y = ..density..)) + 
  geom_histogram(col="grey", breaks = seq(-100, 100, 10)) +
  geom_point(aes(x = diff1, y = 0), color = "red", size = 3)
```
```





<!--
```{r}
split_data <- function(x,y) {
  l <- length(x)
  l1 <- floor(l/2)
  l2 <- l - l1
  ch <- rand_perm(l)
  x1 <- vector("integer", l1)
  for (i in 1:l1) {
    x1[i] <- x[ch[i]]
  }
  x2 <- vector("integer", l2)
  for (i in 1:l2) {
    x2[i] <- x[ch[l1 + i]]
  }
  l <- length(y)
  l1 <- floor(l/2)
  l2 <- l - l1
  ch <- rand_perm(l)
  y1 <- vector("integer", l1)
  for (i in 1:l1) {
    y1[i] <- y[ch[i]]
  }
  y2 <- vector("integer", l2)
  for (i in 1:l2) {
    y2[i] <- y[ch[l1 + i]]
  }
  z1 <- c(x1,y1)
  z2 <- c(x2,y2)
  #print(z1)
  #print(z2)
  diff <- mean(z1) - mean(z2)
  return(diff)
}
split_data(c(1,2,3),c(-4,-5,-6,-7))
```
-->




<!--
We have seen several examples of assessing whether a single sample looks like random draws from a specified chance model.

* Did the Alameda County jury panels look like a random sample from the population of eligible jurors?
* Did the pea plants that Mendel grew have colors that were consistent with the chances he specified in his model?

In all of these cases there was just one random sample, and we were trying to decide how it had been generated. But often, data scientists have to compare two random samples with each other. For example, they might have to compare the outcomes of patients who have been assigned at random to a treatment group and a control group. Or they might have randomized internet users to receive two different versions of a website, after which they would want to compare the actions of the two random groups.

In this chapter, we develop a way of using R to compare two random samples and answer questions about the similarities and differences between them. You will see that the methods we develop have diverse applications. Our examples are from medicine and public health as well as football! `This last sentence may need rewriting if the currently empty sections will remain empty.`

## A/B Testing 

In modern data analytics, deciding whether two numerical samples come from the same underlying distribution is called A/B testing. The name refers to the labels of the two samples, A and B.

We will develop the method in the context of an example. The data come from a sample of newborns in a large hospital system. We will treat it as if it were a simple random sample though the sampling was done in multiple stages. [Stat Labs](https://www.stat.berkeley.edu/~statlabs/) by Deborah Nolan and Terry Speed has details about a larger dataset from which this set is drawn.

### Prerequisites

We will be making use of the tidyverse and the readtext packages in this chapter, so let's load them in. 

```{r, message = FALSE, warning = FALSE}
library(tidyverse)
library(readtext)
```

### Smokers and Nonsmokers 

The table `births` contains the following variables for 1,174 mother-baby pairs: the baby's birth weight in ounces, the number of gestational days, the mother's age in completed years, the mother's height in inches, pregnancy weight in pounds, and whether or not the mother smoked during pregnancy.

```{r message = FALSE}
url <- "https://raw.githubusercontent.com/data-8/materials-su19/master/materials/su19/lec/baby.csv"
births <- read_csv(url)
births
```

One of the aims of the study was to see whether maternal smoking was associated with birth weight. Let's see what we can say about the two variables.

We'll start by selecting just `Birth Weight` and `Maternal Smoker`. There are 715 non-smokers among the women in the sample, and 459 smokers.

```{r}
smoking_and_birthweight <- select(births, 'Maternal Smoker', 'Birth Weight') %>%
  rename(maternal_smoker = "Maternal Smoker", birth_weight = "Birth Weight")

smoking_and_birthweight %>%
  group_by(maternal_smoker) %>%
  count()
```


Let's look at the distribution of the birth weights of the babies of the non-smoking mothers compared to those of the smoking mothers. To generate two overlaid histograms, we will use hist with the optional group argument which is a column label or index. The rows of the table are first grouped by this column and then a histogram is drawn for each one.

```{r dpi=80, fig.align="center", message = FALSE}
ggplot(smoking_and_birthweight) + 
  geom_histogram(aes(x = birth_weight, y = ..density.., fill = maternal_smoker),
                 alpha = 0.8, position = "identity")
```
The distribution of the weights of the babies born to mothers who smoked appears to be based slightly to the left of the distribution corresponding to non-smoking mothers. The weights of the babies of the mothers who smoked seem lower on average than the weights of the babies of the non-smokers.

This raises the question of whether the difference reflects just chance variation or a difference in the distributions in the larger population. Could it be that there is no difference between the two distributions in the population, but we are seeing a difference in the samples just because of the mothers who happened to be selected?

### The Hypotheses

We can try to answer this question by a test of hypotheses. The chance model that we will test says that there is no underlying difference in the popuations; the distributions in the samples are different just due to chance.

Formally, this is the null hypothesis. We are going to have to figure out how to simulate a useful statistic under this hypothesis. But as a start, let's just state the two natural hypotheses.

__Null hypothesis:__ In the population, the distribution of birth weights of babies is the same for mothers who don't smoke as for mothers who do. The difference in the sample is due to chance.

__Alternative hypothesis:__ In the population, the babies of the mothers who smoke have a lower birth weight, on average, than the babies of the non-smokers.

### Test Statistic 

The alternative hypothesis compares the average birth weights of the two groups and says that the average for the mothers who smoke is smaller. Therefore it is reasonable for us to use the difference between the two group means as our statistic.

We will do the subtraction in the order "average weight of the smoking group − average weight of the non-smoking group". Small values (that is, large negative values) of this statistic will favor the alternative hypothesis.

The observed value of the test statistic is about $−9.27$ ounces.

```{r}
means_df <- smoking_and_birthweight %>%
  group_by(maternal_smoker) %>%
  summarize(birth_weight_average = mean(birth_weight))
means_df
```

```{r}
observed_difference <- means_df$birth_weight_average[2] - means_df$birth_weight_average[1]
observed_difference
```

We are going compute such differences repeatedly in our simulations below, so we will define a function to do the job. The function takes three arguments:

* the name of the table of data
* the label of the column that contains the numerical variable whose average is of interest
* the label of the column that contains the Boolean variable for grouping

It returns the difference between the means of the `True` group and the `False` group.

```{r message=FALSE, warning=FALSE}
difference_of_means <- function(df, label, group_label) {
  # @Jerry: https://stackoverflow.com/questions/34186903/error-when-using-dplyr-inside-of-a-function
  # @Jerry: must explain double fencing {{ }}
  means_df <- df %>%
    group_by({{ group_label }}, .groups = 'drop') %>%
    summarize(average = mean({{ label }}), .groups = 'drop')
  return(means_df$average[2] - means_df$average[1])
}

difference_of_means(smoking_and_birthweight, birth_weight, maternal_smoker)
```

That's the same as the value we calculated just earlier. 

### Predicting the Statistic Under the Null Hypothesis

To see how the statistic should vary under the null hypothesis, we have to figure out how to simulate the statistic under that hypothesis. A clever method based on *random permutations* does just that.

If there were no difference between the two distributions in the underlying population, then whether a birth weight has the label True or False with respect to maternal smoking should make no difference to the average. The idea, then, is to shuffle all the labels randomly among the mothers. This is called *random permutation*.

Take the difference of the two new group means: the mean weight of the babies whose mothers have been randomly labeled smokers and the mean weight of the babies of the remaining mothers who have all been randomly labeled non-smokers. This is a simulated value of the test statistic under the null hypothesis.

Let's see how to do this. It's always a good idea to start with the data.

```{r message = FALSE, warning = FALSE}
smoking_and_birthweight
```

There are 1,174 rows in the table. To shuffle all the labels, we will draw a random sample of 1,174 rows without replacement. Then the sample will include all the rows of the table, in random order.

We can use the Table method sample with the optional with_replacement=False argument. We don't have to specify a sample size, because by default, sample draws as many times as there are rows in the table.

```{r}
original_and_shuffled <- smoking_and_birthweight %>%
  mutate(shuffled_label = sample(pull(smoking_and_birthweight, maternal_smoker)))
original_and_shuffled
```

Each baby's mother now has a random smoker/non-smoker label in the column Shuffled Label, while her original label is in Maternal Smoker. If the null hypothesis is true, all the random re-arrangements of the labels should be equally likely.

Let's see how different the average weights are in the two randomly labeled groups.

```{r warning = FALSE, message = FALSE}
shuffled_group_means <- original_and_shuffled %>%
  select(-maternal_smoker) %>% 
  group_by(shuffled_label) %>%
  summarize(birth_weight_average = mean(birth_weight))
shuffled_group_means
```

The averages of the two randomly selected groups are quite a bit closer than the averages of the two original groups. We can use our function `difference_of_means()` to find the two differences.

```{r message = FALSE, warning = FALSE}
difference_of_means(original_and_shuffled, birth_weight, shuffled_label)
```

```{r}
difference_of_means(original_and_shuffled, birth_weight, maternal_smoker)
```

But could a different shuffle have resulted in a larger difference between the group averages? To get a sense of the variability, we must simulate the difference many times.

As always, we will start by defining a function that simulates one value of the test statistic under the null hypothesis. This is just a matter of collecting the code that we wrote above. But because we will later want to use the same process for comparing means of other variables, we will define a function that takes three arguments:

* the name of the table of data
* the label of the column that contains the numerical variable
* the label of the column that contains the Boolean variable for grouping

It returns the difference between the means of two groups formed by randomly shuffling all the labels.

```{r message = FALSE, warning = FALSE}
one_simulated_difference <- function(df, label, group_label, x) {
  # @Jerry: need to discuss pull()
  shuffled_table <- df %>%
    mutate(shuffled_label = sample(pull(df, {{ group_label }})))

  return(difference_of_means(shuffled_table, {{ label }}, shuffled_label))
}
  
```

Run the cell below a few times to see how the output changes.

```{r message = FALSE, warning = FALSE}
one_simulated_difference(smoking_and_birthweight, birth_weight, maternal_smoker)
```

### Permutation Test 

Tests based on random permutations of the data are called permutation tests. We are performing one in this example. In the cell below, we will simulate our test statistic – the difference between the averages of the two groups – many times and collect the differences in an array.

```{r}
num_repetitions <- 5000
differences <- map_dbl(.x = 1:num_repetitions, 
                       .f = one_simulated_difference,
                       df = smoking_and_birthweight, 
                       label = birth_weight,
                       group_label = maternal_smoker)
```

The vector `differences` contains 5,000 simulated values of our test statistic: the difference between the mean weight in the smoking group and the mean weight in the non-smoking group, when the labels have been assigned at random.

### Conclusion of the Test

The histogram below shows the distribution of these 5,000 values. It is the empirical distribution of the test statistic simulated under the null hypothesis. This is a prediction about the test statistic, based on the null hypothesis.

```{r dpi=80, fig.align="center", message = FALSE}
ggplot(tibble(differences)) +
  geom_histogram(aes(x = differences , y = ..density..), color = "gray")
```

Notice how the distribution is centered around 0. This makes sense, because under the null hypothesis the two groups should have roughly the same average. Therefore the difference between the group averages should be around 0.

The observed difference in the original sample is about $−9.27$ ounces, which doesn't even appear on the horizontal scale of the histogram. Let's annotate the histogram with the observed difference to emphasize the discrepency.

```{r dpi=80, fig.align="center", message = FALSE}
ggplot(tibble(differences)) +
  geom_histogram(aes(x = differences , y = ..density..), color = "gray") +
  geom_point(aes(x = -9.2, y = 0), size = 3, color = "red")
```

The observed value of the statistic and the predicted behavior of the statistic under the null hypothesis are inconsistent.

The conclusion of the test is that the data favor the alternative over the null. The average birth weight of babies born to mothers who smoke is less than the average birth weight of babies born to non-smokers.

If you want to compute an empirical P-value, remember that low values of the statistic favor the alternative hypothesis.

```{r}
empirical_p <- sum(differences <= observed_difference) / num_repetitions
empirical_p
```

The empirical P-value is 0, meaning that none of the 5,000 permuted samples resulted in a difference of -9.27 or lower. This is only an approximation. The exact chance of getting a difference in that range is not 0 but it is vanishingly small.

### Another Permutation Test

We can use the same method to compare other attributes of the smokers and the non-smokers, such as their ages. Histograms of the ages of the two groups show that in the sample, the mothers who smoked tended to be younger.

```{r dpi=80, fig.align="center", message = FALSE}
smoking_and_age <- select(births, 'Maternal Smoker', 'Maternal Age') %>%
  rename(maternal_smoker = "Maternal Smoker", maternal_age = "Maternal Age")

ggplot(smoking_and_age) + 
  geom_histogram(aes(x = maternal_age, y = ..density.., fill = maternal_smoker),
                 alpha = 0.8, position = "identity")
```

The observed difference between the average ages is about -0.8 years.

```{r}
observed_age_difference <- difference_of_means(smoking_and_age, maternal_age, maternal_smoker)
observed_age_difference
```

Remember that the difference is calculated as the mean age of the smokers minus the mean age of the non-smokers. The negative sign shows that the smokers are younger on average.

Is this difference due to chance, or does it reflect an underlying difference in the population?

As before, we can use a permutation test to answer this question. If the underlying distributions of ages in the two groups are the same, then the empirical distribution of the difference based on permuted samples will predict how the statistic should vary due to chance.

```{r message = FALSE, warning = FALSE}
num_repetitions <- 5000
age_differences <- map_dbl(.x = 1:num_repetitions, 
                       .f = one_simulated_difference,
                       df = smoking_and_age, 
                       label = maternal_age,
                       group_label = maternal_smoker)
```

The observed difference is in the tail of the empirical distribution of the differences simulated under the null hypothesis.

```{r}
ggplot(tibble(age_differences)) +
  geom_histogram(aes(x = age_differences, y = ..density..), color = "gray") +
  geom_point(aes(x = observed_age_difference, y = 0), size = 3, color = "red")
```

The empirical P-value of the test is the proportion of simulated differences that were equal to or less than the observed difference. This is because low values of the difference favor the alternative hypothesis that the smokers were younger on average.

```{r warning = FALSE}
empirical_p <- sum(age_differences <= observed_age_difference) / num_repetitions
empirical_p
```

The empirical P-value is around 1% and therefore the result is statistically significant. The test supports the hypothesis that the smokers were younger on average.

## Deflategate

TBA

## Causality

TBA

-->


